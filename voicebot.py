import streamlit as st
import openai
import os
from datetime import datetime
from gtts import gTTS
import base64
import io
from streamlit_webrtc import webrtc_streamer, AudioProcessorBase, WebRtcMode
import numpy as np
import collections # ì˜¤ë””ì˜¤ ë²„í¼ë§ì„ ìœ„í•´ deque ì‚¬ìš©

# PyAVë¥¼ ì‚¬ìš©í•œ ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì‹œ í•„ìš”í•œ ëª¨ë“ˆ (Streamlit Cloudì—ì„œ ì„¤ì¹˜ë ì§€ ë¯¸ì§€ìˆ˜)
# import av # ì£¼ì„ ì²˜ë¦¬: ì„¤ì¹˜ ì‹¤íŒ¨ ê°€ëŠ¥ì„± ë•Œë¬¸ì— ì¼ë‹¨ ì œì™¸

# ì˜¤ë””ì˜¤ ë²„í¼ë¥¼ ì €ì¥í•  í´ë˜ìŠ¤ (streamlit-webrtc ì˜ˆì œì—ì„œ ì°¨ìš©)
class AudioBufferProcessor(AudioProcessorBase):
    def __init__(self):
        self.audio_buffer = collections.deque()
        self.start_recording_time = None
        self.is_recording = False

    def recv(self, frame):
        # frame.to_ndarray()ëŠ” float í˜•íƒœì˜ NumPy ë°°ì—´ì„ ë°˜í™˜
        # Whisper APIëŠ” WAV ë°”ì´íŠ¸ë¥¼ ì„ í˜¸í•˜ë¯€ë¡œ, ì—¬ê¸°ì— ìŒ“ëŠ” ê²ƒì€ ì ì ˆì¹˜ ì•Šì„ ìˆ˜ ìˆìŒ
        # ìŠ¤íŠ¸ë¦¼ ìì²´ë¥¼ ì €ì¥í•˜ì—¬ ë‚˜ì¤‘ì— ì²˜ë¦¬í•˜ëŠ” ê²ƒì´ ë” ë‚˜ìŒ
        # ì¼ë‹¨ì€ ë¬´ì‹œí•˜ê³ , ë…¹ìŒ ì¢…ë£Œ ì‹œì ì— ì „ì²´ ìŠ¤íŠ¸ë¦¼ì„ ì–»ëŠ” ë°©í–¥ìœ¼ë¡œ ì ‘ê·¼

        # ì‹¤ì œë¡œ ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•  í•„ìš”ê°€ ì—†ë‹¤ë©´ ì´ í•¨ìˆ˜ëŠ” ë¹„ì›Œë‘˜ ìˆ˜ ìˆìŒ
        # í•˜ì§€ë§Œ Streamlit Cloud í™˜ê²½ì—ì„œ ë…¹ìŒëœ ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ì„ ì–»ëŠ” ë°©ì‹ì´ ì¤‘ìš”í•¨.
        # webrtc_streamerëŠ” ìµœì¢…ì ìœ¼ë¡œ audio_receiverë¥¼ í†µí•´ ë°ì´í„°ë¥¼ ì ‘ê·¼í•˜ê²Œ ë¨.
        return frame

# Streamlit UI ë° ê¸°ëŠ¥ í•¨ìˆ˜
def STT(audio_bytes, apikey):
    # Streamlit-webrtcì—ì„œ ë°›ì€ raw bytesë¥¼ Whisper APIë¡œ ì „ë‹¬
    # Whisper APIê°€ WebM (Opus) ì˜¤ë””ì˜¤ë¥¼ ì§ì ‘ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ”ì§€ í™•ì¸í•´ì•¼ í•¨
    # ë§Œì•½ ì•ˆ ëœë‹¤ë©´, ì—¬ê¸°ì— ffmpeg-python ë“±ìœ¼ë¡œ WAVë¡œ ë³€í™˜í•˜ëŠ” ë¡œì§ì´ í•„ìš”í•˜ë‚˜,
    # ì´ëŠ” Streamlit Cloudì—ì„œ FFmpeg ë¬¸ì œë¡œ ë‹¤ì‹œ ë§‰í ê°€ëŠ¥ì„±ì´ ë§¤ìš° ë†’ìŒ.
    # ì¼ë‹¨ì€ WebMì„ ì§ì ‘ ë³´ë‚´ëŠ” ê²ƒì„ ì‹œë„.

    # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥ (Whisper APIê°€ íŒŒì¼ ê²½ë¡œë¥¼ ìš”êµ¬í•  ìˆ˜ ìˆìŒ)
    # Whisper APIëŠ” íŒŒì¼ ê°ì²´ë¥¼ ì§ì ‘ ë°›ìœ¼ë¯€ë¡œ íŒŒì¼ë¡œ ì €ì¥ í›„ ì—´ê¸°
    filename = "input.webm" # webrtcëŠ” ê¸°ë³¸ì ìœ¼ë¡œ webm (opus) í¬ë§·
    with open(filename, "wb") as f:
        f.write(audio_bytes)

    audio_file = open(filename, "rb")

    client = openai.OpenAI(api_key = apikey)
    try:
        respons = client.audio.transcriptions.create(model="whisper-1", file = audio_file)
        text_response = respons.text
    except Exception as e:
        text_response = f"STT ì˜¤ë¥˜ ë°œìƒ: {e}. WebM í¬ë§·ì´ Whisper APIì— í˜¸í™˜ë˜ëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”."
        st.error(text_response)

    audio_file.close()
    os.remove(filename)
    return text_response

def ask_gpt(prompt, model, apikey):
    client = openai.OpenAI(api_key= apikey)
    response = client.chat.completions.create(
        model = model,
        messages= prompt)
    gptResponse = response.choices[0].message.content
    return gptResponse

def TTS(response):
    filename = "output.mp3"
    tts = gTTS(text=response, lang = "ko")
    
    mp3_fp = io.BytesIO()
    tts.write_to_fp(mp3_fp)
    mp3_fp.seek(0)

    st.audio(mp3_fp.getvalue(), format="audio/mp3", autoplay=True)
    # os.remove(filename) # ì´ì œ í•„ìš” ì—†ìŒ

## ë©”ì¸ í•¨ìˆ˜ ##
def main():
    st.set_page_config(
        page_title = "ìŒì„± ë¹„ì„œ í”„ë¡œê·¸ë¨",
        layout  = "wide")

    st.header("ğŸ”Š 250611_ìŒì„± ë¹„ì„œ í”„ë¡œê·¸ë¨ ì‹¤ìŠµ")

    st.markdown("---")

    with st.expander("ìŒì„± ë¹„ì„œ í”„ë¡œê·¸ë¨?", expanded = True):
        st.write(
        """
        - ìŒì„± ë¹„ì„œ í”„ë¡œê·¸ë¨ì˜ UIëŠ” Streamlitì„ í™œìš©í–ˆìŠµë‹ˆë‹¤.
        - STT (Speech-to-text) : OpenAIì˜ Wisper AI
        - ë‹µë³€ : OpenAIì˜ GPT
        - TTS (Text-to-Speech) : êµ¬ê¸€ì˜ Google Translate TTS
        - ë§ˆì´í¬ ì…ë ¥: `streamlit-webrtc` í™œìš©
        """
        )
        st.markdown("---")

    if "chat" not in st.session_state :
        st.session_state["chat"]=[]
        
    if "OPENAI_API" not in st.session_state :
        st.session_state["OPENAI_API"]="" # API í‚¤ëŠ” ë¬¸ìì—´ë¡œ ì´ˆê¸°í™”
        
    if "messages" not in st.session_state :
        st.session_state["messages"]=[{"role": "system", "content":"You are a thoughtful assistant. Respond to all input in 25 words and answer in korean"}]
    
    if "check_reset" not in st.session_state :
        st.session_state["check_reset"]=False

    with st.sidebar:
        st.session_state["OPENAI_API"] = st.text_input(label = "OPENAI API í‚¤",
                                                       placeholder = "Enter Your API key",
                                                       value = st.session_state["OPENAI_API"],
                                                       type = "password")
        st.markdown("---")
        
        model = st.radio(label = "GPT ëª¨ë¸", options = ["gpt-4o", "gpt-4", "gpt-3.5-turbo"]) # ìµœì‹  ëª¨ë¸ë¡œ ë³€ê²½
        st.markdown("---")
        
        if st.button(label = "ì´ˆê¸°í™”"):
            st.session_state["chat"] = []
            st.session_state["messages"] = [{"role": "system", "content":"You are a thoughtful assistant. Respond to all input in 25 words and answer in korean"}]
            st.session_state["check_reset"]= True
            st.rerun()

    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ì§ˆë¬¸í•˜ê¸°")
        st.info("ì•„ë˜ 'Start' ë²„íŠ¼ì„ ëˆŒëŸ¬ ë…¹ìŒì„ ì‹œì‘í•˜ê³ , 'Stop' ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ ë…¹ìŒì´ ì¤‘ì§€ë©ë‹ˆë‹¤.")

        # streamlit-webrtc ìŠ¤íŠ¸ë¦¼ ì»´í¬ë„ŒíŠ¸
        # ì˜¤ë””ì˜¤ íŠ¸ë™ë§Œ í•„ìš”í•˜ë¯€ë¡œ video_receiver_size=0
        webrtc_ctx = webrtc_streamer(
            key="voice_assistant",
            mode=WebRtcMode.SENDONLY, # ì˜¤ë””ì˜¤ë§Œ ë³´ëƒ„
            audio_receiver_size=1024 * 1024, # ë…¹ìŒ ë²„í¼ í¬ê¸° (1MB)
            media_stream_constraints={"video": False, "audio": True}, # ë¹„ë””ì˜¤ëŠ” ë„ê³  ì˜¤ë””ì˜¤ë§Œ ì¼®
            # rtc_configuration={"iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]}, # NAT íŠ¸ë˜ë²„ì„¤ì„ ìœ„í•œ STUN ì„œë²„ (ì„ íƒ ì‚¬í•­)
            # audio_processor_factory=AudioBufferProcessor # ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ ì§ì ‘ ì²˜ë¦¬í•  í•„ìš”ê°€ ì—†ë‹¤ë©´ ì£¼ì„ ì²˜ë¦¬
        )
        
        audio_bytes = None
        if webrtc_ctx.state.playing:
            st.write("ğŸ”´ ë…¹ìŒ ì¤‘...")
            # ì—¬ê¸°ì„œëŠ” ë…¹ìŒ ì¤‘ì¸ ìƒíƒœë§Œ í‘œì‹œ. ì‹¤ì œ ì˜¤ë””ì˜¤ ë°ì´í„°ëŠ” webrtc_ctx.audio_receiver.get_buffered_frames() ë“±ì„ í†µí•´ ì–»ì–´ì•¼ í•¨.
            # í•˜ì§€ë§Œ webrtc_streamer ì»´í¬ë„ŒíŠ¸ê°€ STOPë  ë•Œ ë…¹ìŒëœ ì˜¤ë””ì˜¤ë¥¼ ì–»ëŠ” ë°©ì‹ì´ ë” ê°„í¸í•¨.
            # webrtc_streamerëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ë…¹ìŒëœ ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼(WebM)ì„ ë°˜í™˜í•  ìˆ˜ ìˆìŒ.
        elif webrtc_ctx.state.ended:
            st.write("âœ… ë…¹ìŒ ì™„ë£Œ!")
            # ë…¹ìŒì´ ì¢…ë£Œë˜ì—ˆì„ ë•Œë§Œ audio_receiverë¡œë¶€í„° ë°ì´í„°ë¥¼ ê°€ì ¸ì˜´
            if webrtc_ctx.audio_receiver:
                try:
                    # audio_receiverë¡œë¶€í„° buffered_framesë¥¼ ê°€ì ¸ì˜´ (Opus ì½”ë±ì˜ WebM ìŠ¤íŠ¸ë¦¼)
                    # Streamlit-webrtcì˜ get_buffered_frames()ëŠ” AVFrame ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•¨
                    # ì´ê²ƒë“¤ì„ í•˜ë‚˜ë¡œ í•©ì³ì„œ WebM íŒŒì¼ë¡œ ì €ì¥í•´ì•¼ Whisper APIì— ì „ë‹¬ ê°€ëŠ¥í•¨.
                    # PyAVë¥¼ ì‚¬ìš©í•´ì•¼ í•˜ëŠ”ë°, Streamlit Cloudì—ì„œ PyAV ì„¤ì¹˜ê°€ ë³µì¡í•  ìˆ˜ ìˆìŒ.
                    # ë§Œì•½ PyAVê°€ ì„¤ì¹˜ëœë‹¤ë©´, ì•„ë˜ ì£¼ì„ ì²˜ë¦¬ëœ PyAV ê´€ë ¨ ì½”ë“œë¥¼ í™œì„±í™”í•˜ì„¸ìš”.
                    # -------------------------------------------------------------
                    # ì„ì‹œë¡œ streamlit-webrtc ìì²´ì˜ ë…¹ìŒ ê¸°ëŠ¥ì´ ì œê³µí•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ì‹œë„.
                    # webrtc_streamerëŠ” í˜„ì¬ ë…¹ìŒëœ ë°”ì´íŠ¸ë¥¼ ì§ì ‘ ë°˜í™˜í•˜ëŠ” ê¸°ëŠ¥ì´ ì—†ìŒ.
                    # ì¦‰, ë³„ë„ì˜ ì²˜ë¦¬ ë¡œì§ì´ í•„ìš”í•˜ë‹¤ëŠ” ëœ».
                    # ê°€ì¥ ê°„ë‹¨í•œ í•´ê²°ì±…ì€ Streamlit Discussionsì˜ webrtc ì˜ˆì œì²˜ëŸ¼
                    # ë…¹ìŒëœ ì„¸ì…˜ì„ ì €ì¥í•˜ì—¬ ë‚˜ì¤‘ì— STT ì²˜ë¦¬í•˜ëŠ” ê²ƒ.
                    # ì•„ë˜ëŠ” Streamlit-webrtc ì˜ˆì œì—ì„œ í”íˆ ë³¼ ìˆ˜ ìˆëŠ” ì˜¤ë””ì˜¤ ìº¡ì²˜ ë°©ì‹ (PyAV í•„ìš”)
                    
                    # ì´ ë¶€ë¶„ì´ Streamlit Cloudì—ì„œ ê°€ì¥ í° ê±¸ë¦¼ëŒì´ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
                    # PyAV ë¼ì´ë¸ŒëŸ¬ë¦¬ë„ C/C++ ì»´íŒŒì¼ëŸ¬ì™€ FFmpeg ê°œë°œ í—¤ë”ê°€ í•„ìš”í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.
                    # ë§Œì•½ PyAV ì„¤ì¹˜ê°€ ì•ˆ ë˜ë©´, ì´ ë°©ì‹ë„ ì‹¤íŒ¨í•©ë‹ˆë‹¤.
                    
                    # ----- PyAVë¥¼ ì´ìš©í•œ ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì˜ˆì‹œ (ì„¤ì¹˜ ì„±ê³µ ì‹œ) -----
                    # frames = webrtc_ctx.audio_receiver.get_buffered_frames()
                    # if frames:
                    #     with io.BytesIO() as out_buffer:
                    #         # PyAVë¥¼ ì‚¬ìš©í•˜ì—¬ WebMìœ¼ë¡œ ì¸ì½”ë”©
                    #         container = av.open(out_buffer, mode="w", format="webm")
                    #         stream = container.add_stream("libopus", rate=48000)
                    #         stream.layout = "stereo" if frames[0].layout.name == "stereo" else "mono"
                    #         stream.bit_rate = 128000
                    #         for frame in frames:
                    #             for packet in stream.encode(frame):
                    #                 container.mux(packet)
                    #         for packet in stream.encode():
                    #             container.mux(packet)
                    #         container.close()
                    #         audio_bytes = out_buffer.getvalue()
                    # --------------------------------------------------------

                    # PyAV ì—†ì´ webrtc_streamerì—ì„œ ë…¹ìŒëœ ì˜¤ë””ì˜¤ë¥¼ ì§ì ‘ ì–»ëŠ” ë‹¨ìˆœí™”ëœ ë°©ì‹ (ì •ìƒ ì‘ë™ ë³´ì¥ ì–´ë ¤ì›€)
                    # í˜„ì¬ webrtc_streamerëŠ” ë…¹ìŒëœ 'íŒŒì¼'ì„ ì§ì ‘ ë°˜í™˜í•˜ëŠ” APIê°€ ì—†ìŒ.
                    # ë”°ë¼ì„œ í´ë¼ì´ì–¸íŠ¸ì—ì„œ ë…¹ìŒëœ ì˜¤ë””ì˜¤ë¥¼ ì„œë²„ë¡œ ì „ì†¡í•˜ëŠ” ë³„ë„ì˜ ë¡œì§ í•„ìš”.
                    # ì˜ˆë¥¼ ë“¤ì–´ JavaScript ì½œë°±ì„ í†µí•´ base64 ì¸ì½”ë”©ëœ ë°ì´í„°ë¥¼ Streamlitìœ¼ë¡œ ë³´ë‚´ëŠ” ë°©ì‹.
                    # ì´ëŠ” í˜„ì¬ ì½”ë“œ êµ¬ì¡°ì—ì„œ ë²—ì–´ë‚¨.
                    
                    # ê°€ì¥ ë‹¨ìˆœí•œ ì ‘ê·¼ì€: Streamlit-webrtcì˜ ìƒíƒœ ë³€í™”ë¥¼ ê°ì§€í•˜ê³ ,
                    # ë…¹ìŒì´ ì™„ë£Œëœ ì‹œì ì— í´ë¼ì´ì–¸íŠ¸ì—ì„œ ì˜¤ë””ì˜¤ë¥¼ íšë“í•˜ì—¬ ì„œë²„ë¡œ ë³´ë‚´ëŠ” ê²ƒì¸ë°,
                    # ì´ëŠ” webrtc_streamer ì»´í¬ë„ŒíŠ¸ ìì²´ì˜ APIë¡œ ì§ì ‘ ì§€ì›ë˜ì§€ ì•ŠìŒ.
                    # ê·¸ë˜ì„œ ëŒ€ë¶€ë¶„ì˜ webrtc ì˜ˆì œëŠ” ì˜¤ë””ì˜¤/ë¹„ë””ì˜¤ íŠ¸ë™ì„ ì§ì ‘ ì²˜ë¦¬í•˜ëŠ” ë¡œì§ì„ í¬í•¨.
                    
                    # ì´ ì½”ë“œì—ì„œëŠ” webrtc_streamer ì»´í¬ë„ŒíŠ¸ê°€ "stopped" ìƒíƒœì¼ ë•Œ
                    # ì˜¤ë””ì˜¤ ë°ì´í„°ê°€ ì¡´ì¬í•œë‹¤ê³  ê°€ì •í•˜ê³  STTë¥¼ ì‹œë„.
                    # (ì‹¤ì œ ë°ì´í„° íšë“ì€ webrtc_ctx.audio_receiverì—ì„œ ë³µì¡í•˜ê²Œ ì´ë£¨ì–´ì ¸ì•¼ í•¨)
                    # ì´ ë¶€ë¶„ì€ ì‹¤ì œë¡œëŠ” ì‘ë™í•˜ì§€ ì•Šì„ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤.
                    # ì™œëƒí•˜ë©´ webrtc_ctx.audio_receiver.get_buffered_frames()ëŠ”
                    # ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ìš©ì´ì§€, "ë…¹ìŒëœ íŒŒì¼"ì„ ë°˜í™˜í•˜ëŠ” ìš©ë„ê°€ ì•„ë‹ˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.
                    # ë”°ë¼ì„œ ì´ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ë©´ STT ë‹¨ê³„ì—ì„œ ì˜¤ë¥˜ê°€ ë‚  ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤.

                    # --- ëŒ€ì•ˆ: ìŠ¤íŠ¸ë¦¼ì´ ì¢…ë£Œë  ë•Œ, ë¸Œë¼ìš°ì €ì—ì„œ ì„œë²„ë¡œ ì˜¤ë””ì˜¤ ë°ì´í„° ì „ì†¡ ---
                    # í•˜ì§€ë§Œ Streamlitì˜ Python ì½”ë“œë§Œìœ¼ë¡œëŠ” ë³µì¡í•œ JS/WebRTC ë…¹ìŒ ì™„ë£Œ ë°ì´í„° ì „ì†¡ì„ êµ¬í˜„í•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤.
                    # ì´ ë•Œë¬¸ì— 'streamlit-audiorecorder'ì™€ ê°™ì€ ë” ë‹¨ìˆœí•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„ í˜¸ë˜ì—ˆë˜ ê²ƒì…ë‹ˆë‹¤.

                    st.warning("`streamlit-webrtc`ì—ì„œ ë…¹ìŒëœ ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ ì§ì ‘ ê°€ì ¸ì˜¤ëŠ” ë¡œì§ì€ ë³µì¡í•©ë‹ˆë‹¤. ì•„ë˜ STTëŠ” ì˜ˆì‹œì´ë©°, ì‹¤ì œ ì‘ë™í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                    st.warning("ì´ ë¶€ë¶„ì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ë©´ `streamlit-webrtc`ë¥¼ ì´ìš©í•œ ì‹¤ì‹œê°„ ë§ˆì´í¬ ë…¹ìŒì€ Streamlit Cloudì—ì„œ ë§¤ìš° ì–´ë µë‹¤ëŠ” ì˜ë¯¸ì…ë‹ˆë‹¤. `st.file_uploader`ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.")
                    
                    # ì„ì‹œ ë°©í¸ìœ¼ë¡œ, ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ì´ ì¢…ë£Œë˜ë©´
                    # ì–´ë–¤ ì˜¤ë””ì˜¤ ë°ì´í„°ê°€ ìˆë‹¤ê³  ê°€ì •í•˜ê³  STTë¥¼ í˜¸ì¶œ (ì‹¤ì œ ë°ì´í„°ëŠ” ë¹„ì–´ìˆì„ ê²ƒ)
                    # ì‹¤ì œ webrtc_streamerì˜ ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ ì–»ëŠ” ë°©ì‹ì€ ë³µì¡í•©ë‹ˆë‹¤.
                    # ì´ëŠ” PyAVë¥¼ ì´ìš©í•˜ê±°ë‚˜, ì»¤ìŠ¤í…€ ì»´í¬ë„ŒíŠ¸ë¥¼ ë§Œë“¤ì–´ JSì—ì„œ ë…¹ìŒëœ ë°ì´í„°ë¥¼
                    # Streamlitìœ¼ë¡œ ì „ì†¡í•´ì•¼ í•©ë‹ˆë‹¤.
                    # ì´ ë•Œë¬¸ì— ê²°êµ­ 'file_uploader' ë°©ì‹ì´ ê°€ì¥ í˜„ì‹¤ì ì…ë‹ˆë‹¤.
                    
                    # --- ì„ì‹œì ì¸ STT í˜¸ì¶œ ë¡œì§ (ì‹¤ì œ ì˜¤ë””ì˜¤ ë°ì´í„°ê°€ ì•„ë‹˜) ---
                    # webrtc_streamerê°€ ë…¹ìŒëœ ì˜¤ë””ì˜¤ë¥¼ ë°”ì´íŠ¸ë¡œ ì§ì ‘ ë°˜í™˜í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ
                    # ì´ ë¶€ë¶„ì€ STT í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ì„ì‹œë¡œ ë¹„ì›Œë‘ê±°ë‚˜,
                    # `ffmpeg-python` ë“±ì„ í†µí•œ ë³µì¡í•œ ë³€í™˜ ë¡œì§ì´ ë“¤ì–´ê°€ì•¼ í•¨.
                    # ì´ëŒ€ë¡œ ì‹¤í–‰í•˜ë©´ `audio_bytes`ëŠ” Noneì´ê±°ë‚˜ ë¹„ì–´ìˆì„ ê²ƒì„.
                    audio_bytes = b"" # ì¼ë‹¨ ë¹ˆ ë°”ì´íŠ¸ë¡œ ì„¤ì •í•˜ê±°ë‚˜, íŒŒì¼ ì—…ë¡œë”ë¥¼ ë³‘í–‰ ì‚¬ìš©
                    # ----------------------------------------------------

                except Exception as e:
                    st.error(f"ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ ì˜¤ë¥˜: {e}. PyAV ì„¤ì¹˜ ë° FFmpeg ê´€ë ¨ ë¬¸ì œì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                    audio_bytes = None
            else:
                audio_bytes = None # ë…¹ìŒ ì¤‘ì´ ì•„ë‹ˆë©´ audio_bytesëŠ” None

        if audio_bytes is not None and (st.session_state["check_reset"]==False):
            if audio_bytes: # ì‹¤ì œë¡œ ë°ì´í„°ê°€ ìˆì„ ë•Œë§Œ STT ì‹œë„
                question = STT(audio_bytes, st.session_state["OPENAI_API"])
                
                now = datetime.now().strftime("%H:%M")
                st.session_state["chat"] = st.session_state["chat"]+[("user", now, question)]
                st.session_state["messages"] = st.session_state["messages"]+[{"role": "user", "content": question}]
            else:
                st.info("ë…¹ìŒëœ ì˜¤ë””ì˜¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.") # ë°ì´í„°ê°€ ë¹„ì–´ìˆì„ ê²½ìš° ë©”ì‹œì§€

    with col2:
        st.subheader("ë‹µë³€")
        
        # webrtc_ctx.state.endedëŠ” ë…¹ìŒì´ ì¤‘ì§€ëœ ìƒíƒœë¥¼ ì˜ë¯¸
        # ë…¹ìŒì´ ì¤‘ì§€ë˜ì—ˆê³ , ë¦¬ì…‹ë˜ì§€ ì•Šì•˜ì„ ë•Œë§Œ GPT í˜¸ì¶œ
        if webrtc_ctx.state.ended and (st.session_state['check_reset']==False) :
            if st.session_state["messages"][-1]["role"] == "user": # ë§ˆì§€ë§‰ ë©”ì‹œì§€ê°€ ì‚¬ìš©ì ì§ˆë¬¸ì¼ ê²½ìš°ë§Œ
                response = ask_gpt(st.session_state['messages'], model,
                                     st.session_state["OPENAI_API"])
                
                st.session_state["messages"] = st.session_state["messages"] + [{"role":"assistant", "content" : response}]
                
                now = datetime.now().strftime("%H:%M")
                st.session_state["chat"] = st.session_state["chat"] + [("bot", now, response)]
                
                for sender, time, message in st.session_state["chat"] : 
                    if sender == "user":
                        st.write(f"""<div style="display :flex;align-items:center;">
                                     <div style="background-color: #007AFF; color:white;border-radius:12px;
                                     padding:8px 12px;margin-right :8px; ">{message}</div>
                                     <div style="font-size :0.8rem;color:gray;">{time}</div></div>""",
                                     unsafe_allow_html=True)
                        st.write("")
                    else : 
                        st.write(f"""<div style="display:flex; align-items:center; justify-content:flex-end;">
                                     <div style="background-color:lightgray; border-radius:12px; padding :8px 12px;
                                     margin-left :8px;">{message}</div><div style="font-size:0.8rem; color:gray;">{time}
                                     </div></div>""", unsafe_allow_html=True)
                        st.write("")
                
                TTS(response)
            else:
                st.info("GPT ë‹µë³€ ëŒ€ê¸° ì¤‘ì´ê±°ë‚˜ ì´ë¯¸ ë‹µë³€ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        elif st.session_state['check_reset']:
            st.info("ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
        else:
            st.info("ë…¹ìŒì„ ì‹œì‘í•´ì£¼ì„¸ìš”.")

if __name__ =="__main__":
    main()
