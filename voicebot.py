import streamlit as st
import openai
import os
from datetime import datetime
from gtts import gTTS
import base64
import io
from streamlit_webrtc import webrtc_streamer, WebRtcMode # AudioProcessorBaseëŠ” í•„ìš” ì—†ì„ ìˆ˜ ìˆìŒ
# import numpy as np # í˜„ì¬ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
# import collections # í˜„ì¬ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ

# AudioBufferProcessor í´ë˜ìŠ¤ ì‚­ì œ (í•„ìš” ì—†ìŒ)

# Streamlit UI ë° ê¸°ëŠ¥ í•¨ìˆ˜
def STT(audio_bytes, apikey):
    # Whisper APIê°€ WebM (Opus) ì˜¤ë””ì˜¤ë¥¼ ì§ì ‘ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ”ì§€ í™•ì¸í•´ì•¼ í•¨
    # ì´ ë¶€ë¶„ì€ ì—¬ì „íˆ FFmpeg ë¬¸ì œê°€ ë°œìƒí•  ìˆ˜ ìˆëŠ” ì ì¬ì  ìœ„í—˜ êµ¬ê°„ì…ë‹ˆë‹¤.
    # streamlit-webrtcê°€ ë…¹ìŒëœ ìµœì¢… íŒŒì¼ì„ ì§ì ‘ ë°˜í™˜í•˜ëŠ” ê²ƒì´ ì•„ë‹˜.
    # audio_bytesê°€ ì‹¤ì œë¡œ WebM í˜•ì‹ì˜ ì˜¤ë””ì˜¤ ë°ì´í„°ì¸ì§€ í™•ì‹ í•˜ê¸° ì–´ë ¤ì›€.
    
    # -------------------------------------------------------------
    # **ê°€ì¥ ì¤‘ìš”í•œ ë¶€ë¶„:**
    # streamlit-webrtcëŠ” ë…¹ìŒëœ 'íŒŒì¼'ì„ ì§ì ‘ ë°˜í™˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
    # webrtc_ctx.audio_receiverë¥¼ í†µí•´ ì‹¤ì‹œê°„ í”„ë ˆì„ì„ ë°›ì•„ì„œ
    # PyAV (ffmpeg í•„ìš”) ë“±ìœ¼ë¡œ ì§ì ‘ ì¸ì½”ë”©í•˜ì—¬ íŒŒì¼ë¡œ ë§Œë“¤ì–´ì•¼ í•©ë‹ˆë‹¤.
    # í˜„ì¬ ì½”ë“œë¡œëŠ” audio_bytesì— ìœ íš¨í•œ ë…¹ìŒ ë°ì´í„°ê°€ ë“¤ì–´ê°€ì§€ ì•ŠìŠµë‹ˆë‹¤.
    # ì´ ì½”ë“œëŠ” STT í•¨ìˆ˜ê°€ í˜¸ì¶œë  ë•Œ `audio_bytes`ì— ì‹¤ì œ ë°ì´í„°ê°€ ìˆì„ ê²ƒì´ë¼ê³ 
    # ê°€ì •í•˜ê³  ì‘ì„±ë˜ì—ˆì§€ë§Œ, webrtc_streamer ì»´í¬ë„ŒíŠ¸ ìì²´ì˜ APIë§Œìœ¼ë¡œëŠ”
    # ë…¹ìŒ ì™„ë£Œ ì‹œì ì— ìµœì¢… ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì–»ê¸°ê°€ ë§¤ìš° ì–´ë µìŠµë‹ˆë‹¤.
    # -------------------------------------------------------------

    # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥ (Whisper APIê°€ íŒŒì¼ ê²½ë¡œë¥¼ ìš”êµ¬í•  ìˆ˜ ìˆìŒ)
    # Whisper APIëŠ” íŒŒì¼ ê°ì²´ë¥¼ ì§ì ‘ ë°›ìœ¼ë¯€ë¡œ íŒŒì¼ë¡œ ì €ì¥ í›„ ì—´ê¸°
    # í˜„ì¬ audio_bytesëŠ” ì‚¬ì‹¤ìƒ ë¹„ì–´ìˆì„ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤.
    if not audio_bytes: # audio_bytesê°€ ë¹„ì–´ìˆìœ¼ë©´ ì˜¤ë¥˜ ë°©ì§€
        return "STT ì˜¤ë¥˜: ë…¹ìŒëœ ì˜¤ë””ì˜¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."

    filename = "input.webm" # webrtcëŠ” ê¸°ë³¸ì ìœ¼ë¡œ webm (opus) í¬ë§·
    try:
        with open(filename, "wb") as f:
            f.write(audio_bytes)

        audio_file = open(filename, "rb")

        client = openai.OpenAI(api_key = apikey)
        respons = client.audio.transcriptions.create(model="whisper-1", file = audio_file)
        text_response = respons.text

    except Exception as e:
        text_response = f"STT ì˜¤ë¥˜ ë°œìƒ: {e}. ì˜¤ë””ì˜¤ ë°ì´í„° ì²˜ë¦¬ ë˜ëŠ” Whisper API í˜¸ì¶œ ë¬¸ì œ."
        st.error(text_response)
    finally:
        if 'audio_file' in locals() and not audio_file.closed:
            audio_file.close()
        if os.path.exists(filename):
            os.remove(filename)
    return text_response

def ask_gpt(prompt, model, apikey):
    client = openai.OpenAI(api_key= apikey)
    response = client.chat.completions.create(
        model = model,
        messages= prompt)
    gptResponse = response.choices[0].message.content
    return gptResponse

def TTS(response):
    tts = gTTS(text=response, lang = "ko")
    
    mp3_fp = io.BytesIO()
    tts.write_to_fp(mp3_fp)
    mp3_fp.seek(0)

    st.audio(mp3_fp.getvalue(), format="audio/mp3", autoplay=True)

## ë©”ì¸ í•¨ìˆ˜ ##
def main():
    st.set_page_config(
        page_title = "ìŒì„± ë¹„ì„œ í”„ë¡œê·¸ë¨",
        layout  = "wide")

    st.header("ğŸ”Š 250611_ìŒì„± ë¹„ì„œ í”„ë¡œê·¸ë¨ ì‹¤ìŠµ")

    st.markdown("---")

    with st.expander("ìŒì„± ë¹„ì„œ í”„ë¡œê·¸ë¨?", expanded = True):
        st.write(
        """
        - ìŒì„± ë¹„ì„œ í”„ë¡œê·¸ë¨ì˜ UIëŠ” Streamlitì„ í™œìš©í–ˆìŠµë‹ˆë‹¤.
        - STT (Speech-to-text) : OpenAIì˜ Wisper AI
        - ë‹µë³€ : OpenAIì˜ GPT
        - TTS (Text-to-Speech) : êµ¬ê¸€ì˜ Google Translate TTS
        - ë§ˆì´í¬ ì…ë ¥: `streamlit-webrtc` í™œìš©
        """
        )
        st.markdown("---")

    if "chat" not in st.session_state :
        st.session_state["chat"]=[]
        
    if "OPENAI_API" not in st.session_state :
        st.session_state["OPENAI_API"]=""
        
    if "messages" not in st.session_state :
        st.session_state["messages"]=[{"role": "system", "content":"You are a thoughtful assistant. Respond to all input in 25 words and answer in korean"}]
    
    if "check_reset" not in st.session_state :
        st.session_state["check_reset"]=False

    with st.sidebar:
        st.session_state["OPENAI_API"] = st.text_input(label = "OPENAI API í‚¤",
                                                       placeholder = "Enter Your API key",
                                                       value = st.session_state["OPENAI_API"],
                                                       type = "password")
        st.markdown("---")
        
        model = st.radio(label = "GPT ëª¨ë¸", options = ["gpt-4o", "gpt-4", "gpt-3.5-turbo"])
        st.markdown("---")
        
        if st.button(label = "ì´ˆê¸°í™”"):
            st.session_state["chat"] = []
            st.session_state["messages"] = [{"role": "system", "content":"You are a thoughtful assistant. Respond to all input in 25 words and answer in korean"}]
            st.session_state["check_reset"]= True
            st.rerun()

    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ì§ˆë¬¸í•˜ê¸°")
        st.info("ì•„ë˜ 'Start' ë²„íŠ¼ì„ ëˆŒëŸ¬ ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¼ì„ ì‹œì‘í•˜ê³ , 'Stop' ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ ì¢…ë£Œë©ë‹ˆë‹¤.")

        # streamlit-webrtc ìŠ¤íŠ¸ë¦¼ ì»´í¬ë„ŒíŠ¸
        webrtc_ctx = webrtc_streamer(
            key="voice_assistant",
            mode=WebRtcMode.SENDONLY, # ì˜¤ë””ì˜¤ë§Œ ë³´ëƒ„
            audio_receiver_size=1024 * 1024, # ë…¹ìŒ ë²„í¼ í¬ê¸° (1MB) - ì‹¤ì œ íŒŒì¼ ì €ì¥ ìš©ë„ê°€ ì•„ë‹˜
            media_stream_constraints={"video": False, "audio": True}, # ë¹„ë””ì˜¤ëŠ” ë„ê³  ì˜¤ë””ì˜¤ë§Œ ì¼®
        )
        
        audio_bytes = None
        # ìŠ¤íŠ¸ë¦¼ì´ í™œì„±í™” ë˜ì–´ ìˆëŠ” ë™ì•ˆ
        if webrtc_ctx.state.playing:
            st.write("ğŸ”´ ë…¹ìŒ ì¤‘...")
            # webrtc_ctx.audio_receiverì—ì„œ í”„ë ˆì„ì„ ê°€ì ¸ì˜¤ëŠ” ê²ƒì€ ì‹¤ì‹œê°„ ì²˜ë¦¬ìš©ì…ë‹ˆë‹¤.
            # ë…¹ìŒì´ 'ëë‚¬ì„ ë•Œ' ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ ì–»ëŠ” ë°©ì‹ì´ ì•„ë‹˜.
            # ì´ ì½”ë“œ ë¸”ë¡ ì•ˆì—ì„œëŠ” ë…¹ìŒëœ ë°”ì´íŠ¸ë¥¼ ì–»ì„ ìˆ˜ ì—†ìŒ.
            
        # ìŠ¤íŠ¸ë¦¼ì´ ë¹„í™œì„±í™” ë˜ì–´ ìˆê³ , ì´ì „ì— ì¬ìƒëœ ì ì´ ìˆë‹¤ë©´ (ì¦‰, 'Stop'ì„ ëˆŒë €ì„ ë•Œ)
        # ì´ ë¶€ë¶„ì´ ê°€ì¥ ë³µì¡í•˜ë©°, webrtc-streamlitì˜ ê¸°ë³¸ì ì¸ í•œê³„ì .
        # webrtc_ctx.audio_receiver.get_buffered_frames()ëŠ” ì‹¤ì‹œê°„ ë²„í¼ì´ë¯€ë¡œ
        # ìŠ¤íŠ¸ë¦¼ì´ ëŠì–´ì§€ë©´ ë°ì´í„°ê°€ ìœ ì‹¤ë˜ê±°ë‚˜ ì ‘ê·¼í•˜ê¸° ì–´ë ¤ìš¸ ìˆ˜ ìˆìŒ.
        # ë”°ë¼ì„œ `streamlit-webrtc` ê³µì‹ ì˜ˆì œ ì¤‘ ë…¹ìŒ í›„ íŒŒì¼ ì €ì¥í•˜ëŠ” ë°©ì‹ì€
        # ëŒ€ë¶€ë¶„ JSë¡œ í´ë¼ì´ì–¸íŠ¸ ì¸¡ì—ì„œ ì²˜ë¦¬í•˜ê±°ë‚˜, ì„œë²„ì—ì„œ í”„ë ˆì„ì„ ê³„ì† ë°›ëŠ” ë°©ì‹.
        # ì¦‰, ì´ ì¡°ê±´ë¬¸ ì•ˆì—ì„œ `audio_bytes`ë¥¼ ì±„ìš°ëŠ” ê²ƒì€ ë§¤ìš° ì–´ë µìŠµë‹ˆë‹¤.
        
        # í•´ê²°ì±…: ì„¸ì…˜ ìƒíƒœì— ë²„í¼ë¥¼ ì €ì¥í•˜ê³ , `playing`ì´ Falseê°€ ë  ë•Œ ì²˜ë¦¬
        # ì´ ë°©ë²•ë„ PyAVë‚˜ ë‹¤ë¥¸ ì˜¤ë””ì˜¤ ì²˜ë¦¬ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ í•„ìš”í•¨ (FFmpeg ì˜ì¡´ì„±)
        # ë”°ë¼ì„œ ê°€ì¥ í˜„ì‹¤ì ì¸ ì ‘ê·¼ì€ `st.file_uploader` ì…ë‹ˆë‹¤.
        
        # --- ì„ì‹œì ì¸ STT í˜¸ì¶œ ë¡œì§ (ì‹¤ì œ ì˜¤ë””ì˜¤ ë°ì´í„°ê°€ ì•„ë‹˜) ---
        # ì‹¤ì œë¡œëŠ” webrtc_ctxì—ì„œ ë…¹ìŒëœ ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ ì§ì ‘ ê°€ì ¸ì˜¤ê¸° ì–´ë µìŠµë‹ˆë‹¤.
        # ì´ ë¶€ë¶„ì€ `st.file_uploader`ë¥¼ ì‚¬ìš©í•˜ê±°ë‚˜, `streamlit-webrtc`ì˜
        # ë” ë³µì¡í•œ ì˜ˆì œ (JS ì—°ë™ ë“±)ë¥¼ ì°¸ê³ í•´ì•¼ í•©ë‹ˆë‹¤.
        # í˜„ì¬ëŠ” STT í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ê¸° ìœ„í•´ ì„ì‹œë¡œ ë¹„ì–´ìˆëŠ” ë°”ì´íŠ¸ë¥¼ ì „ë‹¬í•©ë‹ˆë‹¤.
        # ë”°ë¼ì„œ ì´ ì½”ë“œë¡œëŠ” ë§ˆì´í¬ ë…¹ìŒ-STT-GPT-TTS ì²´ì¸ì´ ë™ì‘í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
        
        # `streamlit-webrtc`ì˜ `state.playing`ì´ `False`ê°€ ë˜ëŠ” ìˆœê°„ì€
        # ì•± ë¡œë“œ ì‹œì , ë˜ëŠ” ì‚¬ìš©ìê°€ 'Stop' ë²„íŠ¼ì„ ëˆŒë €ì„ ë•Œ.
        # ì´ ë•Œ STTë¥¼ í˜¸ì¶œí•˜ê¸° ìœ„í•œ ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ ì–»ëŠ” ê²ƒì´ í•µì‹¬ì¸ë°,
        # `streamlit-webrtc` ì»´í¬ë„ŒíŠ¸ ìì²´ëŠ” 'ë…¹ìŒëœ íŒŒì¼'ì„ ë°˜í™˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
        # ì´ ë•Œë¬¸ì— `audio_bytes`ëŠ” ê³„ì† ë¹„ì–´ìˆê±°ë‚˜, ì´ì „ ë°ì´í„°ê°€ ë‚¨ì•„ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        
        # `streamlit-audiorecorder`ê°€ 'record and send' ê°œë…ì´ì—ˆë‹¤ë©´,
        # `streamlit-webrtc`ëŠ” 'stream and process' ê°œë…ì…ë‹ˆë‹¤.
        # ì´ ì°¨ì´ ë•Œë¬¸ì— ë§ˆì´í¬ ë…¹ìŒ -> STTë¡œì˜ ì§ì ‘ì ì¸ ì—°ê²°ì´ ì–´ë µìŠµë‹ˆë‹¤.
        
        # ì´ ì˜ˆì‹œ ì½”ë“œëŠ” STT í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•  ìˆ˜ ìˆë„ë¡ êµ¬ì¡°ë¥¼ ë§ì·„ì§€ë§Œ,
        # ì‹¤ì œ ë§ˆì´í¬ ë…¹ìŒ ë°ì´í„°ê°€ STTë¡œ ì „ë‹¬ë˜ì§€ëŠ” ì•Šì„ ê²ƒì…ë‹ˆë‹¤.
        
        # ë§Œì•½ webrtc_ctx.audio_receiver.get_buffered_frames()ë¥¼ í†µí•´ ë°ì´í„°ë¥¼ ì–»ê³  ì‹¶ë‹¤ë©´,
        # ì´ëŠ” PyAV ë“±ì„ í†µí•´ WebMìœ¼ë¡œ ì¸ì½”ë”©í•˜ëŠ” ë³„ë„ì˜ ë³µì¡í•œ ë¡œì§ì´ í•„ìš”í•˜ë©°,
        # PyAV ì„¤ì¹˜ ì‹œ FFmpeg ë¬¸ì œê°€ ë‹¤ì‹œ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        
        # ë”°ë¼ì„œ ì•„ë˜ STT í˜¸ì¶œì€ **ì‹¤ì œ ë§ˆì´í¬ ë…¹ìŒ ë°ì´í„°ê°€ ì•„ë‹˜**ì„ ì¸ì§€í•´ì•¼ í•©ë‹ˆë‹¤.
        # ì´ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ë©´ STTê°€ "ë…¹ìŒëœ ì˜¤ë””ì˜¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤" ë˜ëŠ” ìœ ì‚¬í•œ ì˜¤ë¥˜ë¥¼ ë°˜í™˜í•  ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤.
        
        if not webrtc_ctx.state.playing and webrtc_ctx.audio_receiver: # 'playing'ì´ falseì´ê³ , receiverê°€ í™œì„±í™”ëœ ì ì´ ìˆë‹¤ë©´
            # ì´ ë¡œì§ì€ `streamlit-webrtc`ì˜ ì‹¤ì œ ì‚¬ìš© íŒ¨í„´ê³¼ ë‹¤ë¦…ë‹ˆë‹¤.
            # ì‹¤ì œë¡œëŠ” `audio_receiver`ì—ì„œ í”„ë ˆì„ì„ ê³„ì† ë°›ì•„ ì²˜ë¦¬í•˜ëŠ” ë³„ë„ì˜ ìŠ¤ë ˆë“œ/í”„ë¡œì„¸ìŠ¤ê°€ í•„ìš”í•©ë‹ˆë‹¤.
            st.warning("`streamlit-webrtc`ì—ì„œ ë…¹ìŒëœ ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ ì§ì ‘ ê°€ì ¸ì˜¤ëŠ” ê²ƒì€ ë³µì¡í•©ë‹ˆë‹¤. ì´ ë¶€ë¶„ì€ STTë¥¼ í…ŒìŠ¤íŠ¸í•˜ê¸° ìœ„í•œ ì˜ˆì‹œì´ë©°, ì‹¤ì œ ë§ˆì´í¬ ë…¹ìŒ ë°ì´í„°ê°€ ì•„ë‹ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            audio_bytes = b"" # ì„ì‹œë¡œ ë¹ˆ ë°”ì´íŠ¸ë¥¼ ì „ë‹¬
            # ì‹¤ì œ ë°ì´í„°ë¥¼ ì–»ìœ¼ë ¤ë©´ ë‹¤ìŒê³¼ ê°™ì€ ë³µì¡í•œ ê³¼ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.
            # 1. webrtc_ctx.audio_receiverì—ì„œ `get_buffered_frames()` ë˜ëŠ” `consume_buffered_frames()`ë¥¼ ì§€ì†ì ìœ¼ë¡œ í˜¸ì¶œ
            # 2. PyAVë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ í”„ë ˆì„ë“¤ì„ WebM ì»¨í…Œì´ë„ˆë¡œ ì¸ì½”ë”©í•˜ì—¬ ë©”ëª¨ë¦¬ì— ì €ì¥
            # 3. ë…¹ìŒ ì¢…ë£Œ ì‹œ, ë©”ëª¨ë¦¬ì˜ WebM ë°ì´í„°ë¥¼ ìµœì¢… audio_bytesë¡œ ì‚¬ìš©

        if audio_bytes is not None and (st.session_state["check_reset"]==False):
            if audio_bytes: # ì‹¤ì œë¡œ ë°ì´í„°ê°€ ìˆì„ ë•Œë§Œ STT ì‹œë„ (í˜„ì¬ëŠ” ê±°ì˜ ì—†ì„ ê²ƒì„)
                question = STT(audio_bytes, st.session_state["OPENAI_API"])
                
                now = datetime.now().strftime("%H:%M")
                st.session_state["chat"] = st.session_state["chat"]+[("user", now, question)]
                st.session_state["messages"] = st.session_state["messages"]+[{"role": "user", "content": question}]
            else:
                st.info("ë…¹ìŒëœ ì˜¤ë””ì˜¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.") # ì´ ë©”ì‹œì§€ê°€ ê³„ì† ëœ° ê²ƒì…ë‹ˆë‹¤.

    with col2:
        st.subheader("ë‹µë³€")
        
        # `streamlit-webrtc`ì˜ 'Stop' ë²„íŠ¼ í´ë¦­ í›„ STTê°€ ì²˜ë¦¬ë  ë•Œ GPT í˜¸ì¶œ
        # `webrtc_ctx.state.playing`ì´ `False`ì´ë©´ì„œ
        # ë§ˆì§€ë§‰ ìœ ì € ë©”ì‹œì§€ê°€ ìˆê³ , ë¦¬ì…‹ ìƒíƒœê°€ ì•„ë‹ ë•Œ.
        if not webrtc_ctx.state.playing and (st.session_state['check_reset']==False) and \
           st.session_state["messages"][-1]["role"] == "user": # ë§ˆì§€ë§‰ ë©”ì‹œì§€ê°€ ì‚¬ìš©ì ì§ˆë¬¸ì¼ ê²½ìš°ë§Œ
            
            response = ask_gpt(st.session_state['messages'], model,
                                 st.session_state["OPENAI_API"])
            
            st.session_state["messages"] = st.session_state["messages"] + [{"role":"assistant", "content" : response}]
            
            now = datetime.now().strftime("%H:%M")
            st.session_state["chat"] = st.session_state["chat"] + [("bot", now, response)]
            
            for sender, time, message in st.session_state["chat"] : 
                if sender == "user":
                    st.write(f"""<div style="display :flex;align-items:center;">
                                 <div style="background-color: #007AFF; color:white;border-radius:12px;
                                 padding:8px 12px;margin-right :8px; ">{message}</div>
                                 <div style="font-size :0.8rem;color:gray;">{time}</div></div>""",
                                 unsafe_allow_html=True)
                    st.write("")
                else : 
                    st.write(f"""<div style="display:flex; align-items:center; justify-content:flex-end;">
                                 <div style="background-color:lightgray; border-radius:12px; padding :8px 12px;
                                 margin-left :8px;">{message}</div><div style="font-size:0.8rem; color:gray;">{time}
                                 </div></div>""", unsafe_allow_html=True)
                    st.write("")
            
            TTS(response)
        elif st.session_state['check_reset']:
            st.info("ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
        elif not webrtc_ctx.state.playing: # ìŠ¤íŠ¸ë¦¼ì´ ì‹œì‘ë˜ì§€ ì•Šì•˜ê±°ë‚˜ ë©ˆì¶˜ ê²½ìš°
            st.info("ë…¹ìŒì„ ì‹œì‘í•´ì£¼ì„¸ìš”.")


if __name__ =="__main__":
    main()
